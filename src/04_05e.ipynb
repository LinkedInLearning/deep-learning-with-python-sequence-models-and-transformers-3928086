{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55764ae-20f6-403d-b2d1-fd8b80c78c65",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h1>Text Summarization with Pretrained Models in Python</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e620a2-9784-4a2b-98e9-219fd0130997",
   "metadata": {},
   "source": [
    "**Text summarization** is a powerful natural language processing (NLP) task that involves condensing long pieces of text into shorter versions while preserving the key information. There are two main approaches to summarization. **Extractive summarization** selects and combines key sentences from the original text, whereas **abstractive summarization** generates new sentences that capture the main ideas in a more natural and coherent manner. In this tutorial, we will limit our focus to extractive summarization using pretrained models from Hugging Face.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this tutorial, you will be able to:\n",
    "+ **Implement a text summarization pipeline:** Build and run a summarization pipeline that generates concise summaries by rephrasing the input text.\n",
    "+ **Analyze the summarization output:** Understand how to adjust summary length and interpret the generated summary.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "Before we begin, please ensure that you have:\n",
    "+ A working knowledge of Python, including variables, functions, and basic object-oriented programming.\n",
    "+ Familiarity with deep learning model development in Python using Keras and TensorFlow.\n",
    "+ A Python (version 3.x) environment with the `tensorflow`, `keras`, `ipywidgets`, and `transformers` packages installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf2b04-4185-4ac9-a950-86850b6e0b84",
   "metadata": {},
   "source": [
    "Let's also reduce the log verbosity of the `transformers` package. This ensures that we only get error alerts but not informational logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f072f2-547f-4d06-ab3b-f5b926ae6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ada15-d365-4f89-9b3d-9dbe66ad5db2",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15364f4-f165-4d29-82c0-f39d087ce152",
   "metadata": {},
   "source": [
    "## 1. Instantiate a Pipeline for Text Summarization\n",
    "The first thing we do is import the `pipeline` function from the Hugging Face `transformers` package. Then we instantiate a pipeline object called `summarizer` while specifying `\"summarization\"` as the task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ebb3b-8f51-463a-8ace-702e59451899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(task = \"summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff656cb7-3f26-407c-bb7c-899b9dfae181",
   "metadata": {},
   "source": [
    "## 2. Run Text Summarization on Sample Text\n",
    "Now, we provide sample text to summarize. The sample text is an extended passage (approximately 300 words) covering various aspects of artificial intelligence. We then generate a summary using our pipeline, while also adjusting parameters such as `max_length`, `min_length`, `do_sample`, `top_k`, and `top_p` to control the generation process. These parameters help promote more creative and abstractive output by enabling sampling during text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf765085-b514-4626-8116-c26d5582b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "summarize: Artificial intelligence and machine learning have become fundamental components of modern technology, \n",
    "revolutionizing the way industries operate and innovate. In recent years, these technologies have \n",
    "driven transformative changes in sectors ranging from healthcare and finance to transportation and education. \n",
    "For example, machine learning algorithms are now used to predict patient outcomes, optimize financial \n",
    "portfolios, and manage traffic flows in smart cities. As organizations increasingly adopt these \n",
    "technologies, they are able to leverage large amounts of data to derive insights and make informed decisions. \n",
    "\n",
    "Recent advancements in deep learning have further accelerated progress in areas such as computer vision, \n",
    "natural language processing, and autonomous vehicles. Deep learning models, which mimic the human brain's \n",
    "neural networks, can process complex patterns in data, enabling breakthroughs in image recognition, \n",
    "speech synthesis, and natural language understanding. These improvements have led to significant developments \n",
    "in self-driving cars, facial recognition systems, and virtual assistants, technologies that are rapidly \n",
    "becoming integral parts of everyday life.\n",
    "\n",
    "Moreover, AI-powered automation is reshaping the workforce by streamlining operations and reducing the need \n",
    "for manual intervention. Companies are investing in intelligent systems that can learn, adapt, and improve over time, \n",
    "resulting in increased productivity and cost savings. However, the rapid adoption of artificial intelligence \n",
    "also brings challenges, including concerns about data privacy, ethical considerations, and potential \n",
    "job displacement. Policymakers, industry leaders, and researchers must collaborate to ensure that these \n",
    "technologies are developed and deployed responsibly.\n",
    "\n",
    "Ongoing research in artificial intelligence promises even greater advancements. By embracing innovation \n",
    "and addressing ethical and societal concerns, we can harness the power of AI and machine learning to drive \n",
    "sustainable progress and improve the quality of life for people around the world. Furthermore, as advancements \n",
    "in technology continue to evolve, the integration of AI into everyday applications is expected to increase \n",
    "exponentially, creating opportunities for innovative solutions across diverse sectors.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarizer(\n",
    "    sample_text,\n",
    "    max_length = 200,\n",
    "    min_length = 50,\n",
    "    do_sample = True,\n",
    "    top_k = 50,\n",
    "    top_p = 0.95\n",
    ")\n",
    "print(\"Summary:\")\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b01323-e0f7-4507-b46e-da6f28d3aa77",
   "metadata": {},
   "source": [
    "The final summary is printed, providing a synthesized overview of the main ideas in the original text. Feel free to adjust the pipeline parameters to see how they impact the generated text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593bf30-2411-4f66-8b91-2f9f973584c5",
   "metadata": {},
   "source": [
    "## 3. Load a Specific Model from the Model Hub\n",
    "In the previous example, we used the default model for the specified task. However, if we decide to use a model of our own choosing, we can do so. We simply need to specify the model's name when instantiating the pipeline object. This time, we'll use the `\"facebook/bart-large-cnn\"` model. This model is widely used for summarization tasks because it has been fine-tuned on the CNN/DailyMail dataset, which consists of news articles and their corresponding summaries. The BART model employs an encoder-decoder architecture that enables it to generate coherent and fluent summaries by synthesizing and rephrasing the source text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4929bd1-664f-40d2-8c62-516ad00957e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-cnn\"\n",
    "summarizer_ = pipeline(task = \"summarization\", model = model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d6ccd-311d-44ef-a343-7bc7694c302b",
   "metadata": {},
   "source": [
    "Let's pass the same sample text, as before, to this new pipeline to see how it summarizes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a3418d-556d-4f56-bbd6-2872703d2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarizer_(\n",
    "    sample_text,\n",
    "    max_length = 200,\n",
    "    min_length = 50,\n",
    "    do_sample = True,\n",
    "    top_k = 50,\n",
    "    top_p = 0.95\n",
    ")\n",
    "print(\"Summary:\")\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc9acb-55e2-4690-b23c-8fc194e7514f",
   "metadata": {},
   "source": [
    "As expected, the summaries are different. It's always good practice to try several models for any given task. Feel free to select another model from the Model Hub to see how the results vary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53a316d-e283-49af-a9be-2850e8bfb4da",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Note:</b> For guidance on how to choose the right pretrained model for a specific task from the Hugging Face Model Hub, watch the course video titled <b>\"Choosing the right Model from the Hugging Face Hub\"</b>.</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
