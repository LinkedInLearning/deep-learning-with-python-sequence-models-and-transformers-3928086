{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55764ae-20f6-403d-b2d1-fd8b80c78c65",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h1>Sentiment Analysis with Pretrained Models in Python</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e620a2-9784-4a2b-98e9-219fd0130997",
   "metadata": {},
   "source": [
    "**Sentiment analysis** is one of the most common text classification tasks in natural language processing (NLP). It involves determining the polarity of text (i.e., categorizing it as positive, negative, or neutral). In this tutorial, we will use pretrained models from the Hugging Face Model Hub to perform sentiment analysis.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this tutorial, you will be able to:\n",
    "+ **Build a text classification pipeline for sentiment analysis:** Create a pipeline for sentiment classification using the high-level API provided by Hugging Face.\n",
    "+ **Interpret model outputs:** Analyze and interpret the model’s predictions, including sentiment labels and confidence scores.\n",
    "\n",
    "## Prerequisites\n",
    "Before we begin, please ensure that you have:\n",
    "+ A working knowledge of Python, including variables, functions, loops, and basic object-oriented programming.\n",
    "+ Familiarity with deep learning model development in Python using Keras and TensorFlow.\n",
    "+ A Python (version 3.x) environment with the `tensorflow`, `keras`, `ipywidgets`, and `transformers` packages installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73db0ce-1bbc-4dc7-8215-a14ee1bb1b91",
   "metadata": {},
   "source": [
    "Let's also reduce the log verbosity of the `transformers` package. This ensures that we only get error alerts but not informational logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d027b69e-ce08-400c-b44f-d968477795a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc901c5-09b3-44da-bf2e-039115b3f453",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4510f5e-773b-4e8a-9a46-2518540b2a2b",
   "metadata": {},
   "source": [
    "## 1. Instantiate a Pipeline for Sentiment Analysis\n",
    "The first thing we do is import the `pipeline` function from the Hugging Face `transformers` package. Then we instantiate a pipeline object called `sentiments` while specifying `\"sentiment-analysis\"` as the task. Note that the \"sentiment-analysis\" task is an alias for \"text-classification\", so we could have also set `\"text-classification\"` as the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b00c882-1e7d-4657-859c-ac0f67c2c8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21cda77c-0265-4f26-9eb6-753776af0822",
   "metadata": {},
   "source": [
    "## 2. Run Sentiment Analysis on Sample Text\n",
    "Now that we've instantiated a sentiment analsysis pipeline, let's pass some text to it for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b151a5cb-7955-4fb6-a531-e421f2b38b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"I absolutely love this product. It exceeded all my expectations!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0600cc0-6d4a-40e7-8e99-19e973609e7b",
   "metadata": {},
   "source": [
    "The output includes a `'label'` (indicating either **POSITIVE** or **NEGATIVE**) and a `'score'`, which quantifies the model’s confidence in its prediction. We see that the model classified this particular piece of text as positive, with a confidence score of 0.9999."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9418361c-eed6-4040-bd09-11d668f3dbed",
   "metadata": {},
   "source": [
    "Next, let's pass several sentences to the pipeline to see how it classifies them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74412bc1-b3ed-491e-825d-d55b9bb99877",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = [\n",
    "    \"I absolutely love this product. It exceeded all my expectations!\",\n",
    "    \"The battery life is terrible. I regret buying it.\",\n",
    "    \"It's okay, not great but not awful either.\",\n",
    "    \"I'm not sure this is what I want.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096941bb-16ca-4eee-af14-cd0d9c9826fc",
   "metadata": {},
   "source": [
    "These predictions demonstrate how the model interprets various expressions of sentiment. Even sentences that might seem ambiguous (e.g., \"It's okay, not great but not awful either.\") receive a classification along with a confidence score, providing insight into the model’s decision-making process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d561eb-f86b-40bc-92ec-0eb5fa226f1f",
   "metadata": {},
   "source": [
    "## 3. Load a Specific Model from the Model Hub\n",
    "In the previous example, we used the default model for the specified task. However, if we decide to use a model of our own choosing, we can do so. We simply need to specify the model's name when instantiating the pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c4c41-3ce2-4658-b036-00b7137058d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29e1b7ab-82ea-4ddb-a947-3f5849a77152",
   "metadata": {},
   "source": [
    "Let's pass the same sentences, as before, to this new pipeline to see how it classifies them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff62949-5947-4595-a7f7-26be5d440209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94557b81-8e1d-4557-a024-7b6f96ba3f25",
   "metadata": {},
   "source": [
    "The results are pretty similar except for the third sentence, which is classified as negative this time around. This points to the differences in the training data and manner in which the two models were trained. It's always good practice to try several models for any given task. Feel free to select another model from the Model Hub to see how the results vary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63903baa-0771-498f-9aef-731f81d3c520",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Note:</b> For guidance on how to choose the right pretrained model for a specific task from the Hugging Face Model Hub, watch the course video titled <b>\"Choosing the right Model from the Hugging Face Hub\"</b>.</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
